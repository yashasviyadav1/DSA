# PYQ Solution - **MT-CSE-18-13(iii): Introduction to Intelligent Systems**:

![page1](https://i.ibb.co/5XyW7L23/image.png)

![page2](https://i.ibb.co/XfzzmfVY/image.png)

![page3](https://i.ibb.co/nNVgyxfN/image.png)

**Compulsory Question**

**Question 1. (a) Difference between Crossover and Mutation**
These are the two primary operators in Genetic Algorithms (Unit 1 & 2 of your syllabus).

| **Feature** | **Crossover (Recombination)** | **Mutation** |
| --- | --- | --- |
| **Definition** | Combines genetic information from **two parents** to produce new offspring. | Randomly alters one or more gene values in a **single individual**. |
| **Goal** | **Exploitation:** It converges towards a known good solution by mixing existing good traits. | **Exploration:** It introduces random diversity to prevent getting stuck in local optima. |
| **Magnitude** | Makes **large jumps** in the search space. | Makes **small, local changes** to the solution. |
| **Probability** | Occurs with **high probability** (usually 60-90%). | Occurs with **very low probability** (usually < 1%). |

**1. (b) Differentiate between DFS and BFS**

| **Feature** | **Depth First Search (DFS)** | **Breadth First Search (BFS)** |
| --- | --- | --- |
| **Strategy** | Explores as deep as possible along each branch before backtracking. | Explores neighbor nodes first, visiting layer-by-layer. |
| **Data Structure** | Uses a **Stack** (LIFO). | Uses a **Queue** (FIFO). |
| **Memory (Space)** | **Low:** $O(d)$ (Linear). Good for memory-constrained systems. | **High:** $O(b^d)$ (Exponential). Needs to store the whole level. |
| **Completeness** | **No:** Can get stuck in infinite loops or infinite paths. | **Yes:** Guaranteed to find a solution if one exists. |
| **Optimality** | **No:** Just finds the *first* solution, not necessarily the shortest. | **Yes:** Guaranteed to find the shallowest (shortest) path. |

**1. (c) Different Categories of Knowledge Representation Schemes**
Knowledge Representation is generally categorized into four main types:
1. **Logical Representation:**

- Uses formal logic to represent facts and rules.
- **Examples:** Propositional Logic, First-Order Logic (Predicate Logic).
- *Pros:* Precise and unambiguous.

2. **Semantic Network Representation:**

- Represents knowledge as a graph of **nodes** (concepts) and **arcs** (relationships)
- **Example:** `Bird --(is a)--> Animal`.

3. **Frame-Based Representation:**

- Uses data structures called **Frames** (similar to objects/classes in programming) with **slots** to store attributes and values.
- **Extension:** **Scripts** are used to represent stereotypical sequences of events (e.g., "Going to a restaurant").

4. **Production Rules (Rule-based):**

- Uses **If-Then** rules to represent knowledge.
- **Example:** `IF (temperature > 100) THEN (alarm = ON)`.
****

**1. (d) Differentiate between Supervised and Unsupervised Learning**

| **Feature** | **Supervised Learning** | **Unsupervised Learning** |
| --- | --- | --- |
| **Input Data** | Uses **Labeled Data** (Input + Correct Output is provided). | Uses **Unlabeled Data** (Only Input is provided). |
| **Goal** | To learn a mapping function to **predict** the output for new data. | To discover hidden **structures**, patterns, or groupings in data. |
| **Feedback** | Direct feedback is given (the model knows if it was right or wrong). | No feedback is provided; the model learns by itself. |
| **Main Tasks** | **Classification** (e.g., Is this email spam?) and **Regression** (e.g., House price prediction). | **Clustering** (e.g., Customer segmentation) and **Association**. |
| **Algorithms** | Neural Networks, Support Vector Machines (SVM), Decision Trees. | K-Means Clustering, Apriori Algorithm. |

---

### Unit-3

**Question 2 (a): Difference between Artificial and Biological Neural Networks**

This question asks for a comparison between the biological brain (BNN) and the computer models we build (ANN).

| **Feature** | **Biological Neural Network (BNN)** | **Artificial Neural Network (ANN)** |
| --- | --- | --- |
| **Basic Unit** | The **Neuron** (Soma, Dendrites, Axon, Synapse). | The **Perceptron** (Nodes, Weights, Activation Function). |
| **Processing Speed** | **Slow** (Milliseconds). Signals travel via chemical reactions. | **Fast** (Nanoseconds). Signals travel via electronic circuits. |
| **Processing Style** | **Massively Parallel**. Billions of neurons fire simultaneously. | **Sequential/Parallel**. Mostly sequential matrix math, though GPUs allow some parallelism. |
| **Learning** | **Plasticity/Hebbian Learning**. "Neurons that fire together, wire together." Connections physically grow or shrink. | **Optimization**. Uses mathematical algorithms (like Backpropagation) to adjust numerical weights. |
| **Fault Tolerance** | **High**. Brain cells die daily, but function continues. | **Low**. If a key weight or node is corrupted, the network fails (unless specifically designed with dropout). |
| **Information Storage** | Stored in the **strength of synapses** (chemical concentrations). | Stored in **continuous numeric values** (Weights). |

**Question 2 (b): Write the Genetic Algorithm and discuss the problem of Premature Convergence**

**1. The Genetic Algorithm (GA)**

A Genetic Algorithm is an optimization technique based on natural selection. It follows this standard cycle:

1. **Initialization:** Create a random population of solutions (chromosomes).
2. **Fitness Evaluation:** Test each solution to see how good it is (assign a Fitness Score).
3. **Selection:** Pick the best solutions to be parents (e.g., Roulette Wheel Selection).
4. **Crossover (Mating):** Combine parts of two parents to create new offspring.
5. **Mutation:** Randomly tweak a small part of the offspring to introduce diversity.
6. **Termination:** Repeat until a stopping condition is met (e.g., 100 generations).

**2. The Problem of Premature Convergence**

**Definition:** Premature convergence happens when the population gets stuck at a **Local Optimum** (a "good" solution) way too early, before exploring the rest of the search space for the **Global Optimum** (the "best" solution).

**Why it happens:**

- **Loss of Diversity:** If one decent parent is selected too often, the whole population becomes clones of that parent.
- **Low Mutation Rate:** If mutation is too low, no new genetic material is introduced.

**How to fix it:**

- **Increase Mutation Rate:** Force the algorithm to look in new directions.
- **Use Tournament Selection:** Prevents one "super" individual from dominating the roulette wheel.

**Question 3 (a): What is Fuzzy Logic? Discuss Fuzzy operators with examples**

**What is Fuzzy Logic?**
Standard boolean logic is binary (0 or 1, Black or White). **Fuzzy Logic** allows for degrees of truth (0 to 1, Shades of Grey). It mimics human reasoning where things can be "partially true."

- **Example:** Is 25°C hot?
    - **Boolean:** No (0).
    - **Fuzzy:** It is 0.6 "Hot" and 0.4 "Warm".
    
    **Fuzzy Operators (with Examples)**
    
    Let's assume we have two fuzzy values (Membership values $\mu$):
    
    - $A$ (Alice is Tall) = **0.8**
    - $B$ (Bob is Tall) = **0.4**
    
    **1. Union (Fuzzy OR)**
    
    - **Rule:** Take the **Maximum** value.
    - **Formula:** $\mu(A \cup B) = \max(\mu A, \mu B)$
    - **Example:** Is Alice OR Bob tall?
        
        $\max(0.8, 0.4) = \textbf{0.8}$
        
    
    **2. Intersection (Fuzzy AND)**
    
    - **Rule:** Take the **Minimum** value.
    - **Formula:** $\mu(A \cap B) = \min(\mu A, \mu B)$
    - **Example:** Are Alice AND Bob tall?
    $\min(0.8, 0.4) = \textbf{0.4}$
    
    **3. Complement (Fuzzy NOT)**
    
    - **Rule:** Subtract from 1.
    - **Formula:** $\mu(\neg A) = 1 - \mu A$
    - **Example:** Is Alice NOT tall?
        ◦ $1 - 0.8 = \textbf{0.2}$

**Question 3 (b): Write a note on Fuzzy Neural Networks**

**Source Question:**

A **Fuzzy Neural Network (FNN)** or **Neuro-Fuzzy System** is a hybrid intelligent system that combines the human-like reasoning of Fuzzy Logic with the learning capability of Neural Networks.

**Why combine them?**

- **Neural Networks** are "Black Boxes." They learn well but cannot explain *why* they made a decision.
- **Fuzzy Systems** are "Interpretable." They use clear rules (IF-THEN), but they cannot learn; humans must manually tune them.
- **FNNs** give you the best of both worlds: The system learns from data (adjusting weights) but represents knowledge as readable Fuzzy Rules.

**Architecture (ANFIS - Adaptive Neuro-Fuzzy Inference System):**

1. **Layer 1 (Input):** Passes crisp values (e.g., Speed = 50).
2. **Layer 2 (Fuzzification):** Neural nodes act as membership functions (converts 50 to "0.7 Fast").
3. **Layer 3 (Rule Base):** Neurons represent IF-THEN rules (IF Fast, THEN Brake).
4. **Layer 4 (Output):** Combines the rules and converts back to a crisp number.

---

### Unit-2

**Question 4 (a): Desirable Qualities of a Search Technique & Simulated Annealing**

**1. Desirable Qualities of a Search Technique**

To evaluate any AI search algorithm, we look for four standard properties (qualities):

1. **Completeness:** Is the algorithm guaranteed to find a solution if one exists?
2. **Optimality:** Does the algorithm find the best solution (lowest cost) or just *any* solution?
3. **Time Complexity:** How long does it take to find a solution? (measured in generated nodes).
4. **Space Complexity:** How much memory is needed to perform the search?

**2. Simulated Annealing**

**Simulated Annealing** is a probabilistic local search algorithm used to find the global maximum or minimum. It is inspired by the metallurgical process of **Annealing**, where metal is heated to a high temperature and then slowly cooled to crystallize into a strong, structured state.

- **How it works:**
    - It starts with a random solution.
    - It maintains a variable called **Temperature ($T$)**.
        - At **High $T$**: The algorithm acts "crazy." It accepts bad moves (moves that increase error) with high probability. This allows it to jump out of **Local Optima** (valleys).
        - At **Low $T$**: As the system "cools down," it becomes strict. It stops accepting bad moves and acts like simple Hill Climbing, settling into the nearest peak.
        - Key Formula: The probability of accepting a worse move is given by the Boltzmann distribution: $P = e^{\frac{\Delta E}{T}}$
    - (Where $\Delta E$ is the change in quality and $T$ is current temperature).

**Question 4 (b): Depth First Search with Iterative Deepening (IDS)**

Definition: Iterative Deepening Search (IDS) is a strategy that combines the benefits of DFS (low memory) and BFS (guaranteed to find the shortest path).

How it works:
Instead of diving to infinite depth immediately, IDS runs DFS repeatedly with a gradually increasing Depth Limit ($l$).
1. Run DFS with Limit = 0 (Check root).
2. Run DFS with Limit = 1 (Check root + immediate neighbors).
3. Run DFS with Limit = 2.
4. ...Repeat until the goal is found.

**Limitations:**

1. **Repeated Work:** The main criticism is that it regenerates the top levels of the tree multiple times. For example, the root node is generated in every single iteration. (However, mathematically, this overhead is usually negligible compared to the size of the bottom layer).
2. **Slower than BFS:** It is slightly slower than pure BFS due to the overhead of revisiting nodes.

---

**Question 5 (a): Best First Search Algorithm & Difference from Hill Climbing**

**Algorithm: Best First Search (Greedy)**

Best First Search uses a **Heuristic function $h(n)$** to estimate how close a node is to the goal. It always expands the node that *appears* to be closest to the goal.

**Steps:**

1. **Initialize:** Put the Start Node into a Priority Queue (called `OPEN` list).
2. **Loop:** While `OPEN` is not empty:
- **Remove:** The node with the **lowest $h(n)$ value** (best score) from `OPEN`. Call it `current`.
- **Check:** If `current` is the Goal, return **SUCCESS**.
- **Expand:** Generate all children of `current`.
- **Add:** For each child:
    - Calculate its $h(n)$.
    - If it hasn't been visited, add it to the `OPEN` list.
1. **Failure:** If `OPEN` is empty and no goal is found, return **FAIL**.

| **Feature** | **Best First Search** | **Hill Climbing** |
| --- | --- | --- |
| **Memory** | **Global Search:** It keeps a list of all open candidates (`OPEN` list). If the current path looks bad, it can jump back to a previous promising node. | **Local Search:** It keeps **only the current node**. It forgets where it came from and cannot backtrack if it gets stuck. |
| **Completeness** | **Complete** (in finite spaces), as it will eventually try other paths. | **Incomplete:** It can easily get stuck in Local Maxima or Ridges. |

**Question 5 (b): Breadth First Search (BFS) Algorithm & Complexities**

**Algorithm: BFS**
BFS explores the graph layer-by-layer. It uses a **Queue (FIFO)** data structure.
**Steps:**
1. **Start:** Create a Queue `Q` and mark the Start Node as `visited`.
2. **Enqueue:** Add Start Node to `Q`.
3. **Loop:** While `Q` is not empty:

- **Dequeue:** Remove the front node `u` from `Q`.
- **Process:** Check if `u` is the Goal. If yes, stop.
- **Expand:** For every neighbor `v` of `u`:
    - If `v` is unvisited:
    - Mark `v` as `visited`.
    - Enqueue `v` into `Q`.

**Complexities**
(Using $b$ = branching factor, $d$ = depth of solution)

1. **Time Complexity:** **$O(b^d)$**

- In the worst case, BFS generates every node at every level up to depth $d$.
- $1 + b + b^2 + ... + b^d \approx O(b^d)$.
- **Space Complexity:** **$O(b^d)$**
    ◦ This is the biggest weakness of BFS. It must store all the leaf nodes of the current frontier in memory simultaneously. If the graph is deep, it runs out of RAM very quickly.

---

### **Unit-3**

**Question 6 (a): Difference between Semantic Networks and Conceptual Graphs**

Both are graphical ways to represent knowledge, but they differ in formality and structure.

| **Feature** | **Semantic Networks** | **Conceptual Graphs (CG)** |
| --- | --- | --- |
| **Structure** | A directed graph consisting of **Nodes** (Concepts/Objects) and **Arcs** (Relationships). | A bipartite graph with two specific types of nodes: **Concept Nodes** (Box) and **Relation Nodes** (Oval/Circle). |
| **Simplicity** | Simple and intuitive. Easy to read for humans. | More formal and structured. Closer to First-Order Logic. |
| **Relations** | Relationships are just labeled arrows between two nodes (Binary relations). | Relations are explicit nodes. This allows for n-ary relations (relationships involving 3+ objects). |
| **Example** | `Bird --(is-a)--> Animal` | `[Bird] -> (is-a) -> [Animal]` |
| **Expressiveness** | Often lacks precise semantics (e.g., hard to distinguish between a "specific bird" and the "class of birds"). | Highly expressive. Can clearly distinguish between Types (Classes) and Individuals. |

**Question 6 (b): What is Propositional Logic? Discuss the Resolution Mechanism**

**1. Propositional Logic (PL)**
Propositional Logic is the simplest form of logic where statements are made about specific facts which can be either **True** or **False**.

- **Atomic Sentences:** Basic facts represented by symbols (e.g., $P$: "It is raining", $Q$: "I am wet").
- **Connectives:** These symbols are combined using logical operators:
    - $\land$ (AND)
    - $\lor$ (OR)
    - $\neg$ (NOT)
    - $\rightarrow$ (Implication)
    - **limitation:** It treats facts as "whole chunks." It cannot see inside a fact (e.g., it cannot express "All men are mortal" without listing every single man).

**2. The Resolution Mechanism**
Resolution is a specific **inference rule** used for theorem proving (making computers "think" and derive new truths). It is primarily used in **Proof by Contradiction**.
The Rule:
If we know that $(A \lor B)$ is true, AND we know that $(\neg A \lor C)$ is true, we can cancel out $A$ and conclude that $(B \lor C)$ must be true.

$\frac{A \lor B, \quad \neg A \lor C}{B \lor C}$

**How it works (The Algorithm):**
1. **Convert to CNF:** Convert all knowledge into "Clause Form" (statements linked only by OR and AND).
2. **Negate the Goal:** Assume the thing you want to prove is **False**.
3. **Apply Resolution:** Look for two clauses where one contains a literal (e.g., $P$) and the other contains its negation ($\neg P$). Combine them and cancel $P$.
4. **Contradiction:** Keep doing this until you reach an **Empty Clause** (a logical impossibility). This proves your original assumption was wrong, and the Goal is effectively **True**.

**Question 7 (a): Write a short note on Script Knowledge Representation Scheme**

**Definition:**
A **Script** is a structured representation used to describe a **stereotypical sequence of events** in a particular context. It was introduced by Roger Schank.

**Why use it?**
It helps AI understand situations by filling in missing details. If I say "I went to a restaurant," the AI uses the "Restaurant Script" to assume I also *ate food* and *paid money*, even if I didn't explicitly say so.

**Key Components of a Script:**

1. **Entry Conditions:** What must be true before the script starts (e.g., The customer is hungry and has money).
2. **Results:** What is true after the script ends (e.g., The customer is full and has less money).
3. **Props:** The objects involved (e.g., Tables, Menu, Food, Money).
4. **Roles:** The people involved (e.g., Customer, Waiter, Chef).
5. **Scenes:** The sequence of events:
    - *Entering*
    - *Ordering*
    - *Eating*
    - *Exiting*

**Question 7 (b): What is First Order Predicate Logic (FOPL)? How is it different from Propositional Logic?**

**1. First Order Predicate Logic (FOPL)**

FOPL is a more powerful extension of Propositional Logic. Unlike Prop Logic, which looks at sentences as whole units, FOPL breaks sentences down into **Objects** and **Predicates** (properties).

- It introduces **Variables** ($x, y$).
- It introduces **Quantifiers**:
    - **Universal ($\forall$):** "For all" (e.g., $\forall x, \text{Man}(x) \rightarrow \text{Mortal}(x)$).
    - **Existential ($\exists$):** "There exists" (e.g., $\exists x, \text{King}(x)$).

**2. Difference from Propositional Logic**

| **Feature** | **Propositional Logic (PL)** | **First Order Predicate Logic (FOPL)** |
| --- | --- | --- |
| **Granularity** | **Coarse-grained.** Represents facts as atomic symbols ($P$). | **Fine-grained.** Breaks facts into Objects and Predicates ($\text{Rich}(\text{John})$). |
| **Quantifiers** | **None.** Cannot handle general statements about groups. | **Has Quantifiers ($\forall, \exists$).** Can express "All", "Some", "None". |
| **Variables** | No variables. Specific facts only. | Uses variables (e.g., $x, y$) to represent unknown objects. |
| **Expressive Power** | **Low.** cannot express "All students like AI." | **High.** Can express complex relationships and generalizations. |
| **Example** | $P$ = "Socrates is a man." | $\text{Man}(\text{Socrates})$ |

---

### Unit-4

**Question 8 (a): What do you understand by Stanford Certainty Factor Algebra? Explain.**

**Stanford Certainty Factor (CF) Algebra** is a technique used to manage uncertainty in rule-based expert systems. It was famously developed for **MYCIN**, an expert system designed to diagnose bacterial infections.
Why was it needed?
Standard probability theory requires a lot of statistical data (priors) that doctors often don't have. Certainty Factors allow experts to express their "confidence" or "belief" in a rule without needing perfect statistics.
Key Components:
The Certainty Factor ($CF$) is derived from two separate measures:

1. **Measure of Belief ($MB$):** How much the evidence *supports* the hypothesis.
2. **Measure of Disbelief ($MD$):** How much the evidence *refutes* the hypothesis.
The Formula:
$CF(H, E) = MB(H, E) - MD(H, E)$
    1. **Range:** The value of $CF$ ranges from **-1 to +1**.
        1. **+1:** Definitely True.
        2. **0:** Unknown / No knowledge.
        3. **-1:** Definitely False.

Propagation Rules (The "Algebra"):

How do we combine confidence when we have multiple rules?

- **AND Operator:** $CF(A \land B) = \min(CF(A), CF(B))$
- **OR Operator:** $CF(A \lor B) = \max(CF(A), CF(B))$
- **Sequential Combination:** If Rule 1 gives a CF of $X$ and Rule 2 gives a CF of $Y$ for the same conclusion, the combined CF is calculated using a specific formula (e.g., $X + Y(1 - X)$) to strengthen the belief.

**Question 8 (b): Differentiate between Induction and Abduction form of Learning.**

Both are methods of logical reasoning used in machine learning and AI, but they work in opposite directions.

| **Feature** | **Inductive Learning (Generalization)** | **Abductive Learning (Explanation)** |
| --- | --- | --- |
| **Direction** | **Specific $\rightarrow$ General** | **Observation + Rule $\rightarrow$ Cause** |
| **Goal** | To learn a **general rule** from specific examples. | To find the **best explanation** or diagnosis for an observation. |
| **Logic** | "I see 100 white swans. Therefore, ALL swans are white." | "The grass is wet. Rain makes grass wet. Therefore, it *probably* rained." |
| **Validity** | **Not logically guaranteed.** (The 101st swan might be black). | **Not logically guaranteed.** (The grass might be wet because of a sprinkler). |
| **AI Use Case** | **Supervised Learning** (Training a Neural Network). | **Diagnostics** (Medical AI, Fault detection). |
| **Equation** | Given $Data \rightarrow Output$, find the Function $f(x)$. | Given $Output$ and Rule $A \rightarrow B$, infer $A$. |

**Question 9 (a): What is Evolutionary Algorithm? Discuss.**

**Evolutionary Algorithms (EA)** are a subset of AI based on the biological principles of **Natural Selection** and **Darwinian Evolution**. They are optimization algorithms used to solve problems where traditional methods fail.

**Core Concept:**
Instead of trying to "calculate" the answer directly, EAs "breed" a population of potential answers and let the bad ones die out while the good ones reproduce.

**The Main Family Members:**

1. **Genetic Algorithms (GA):** Focuses on optimizing strings of numbers (chromosomes).
2. **Genetic Programming (GP):** Evolves actual computer programs or code.
3. **Evolution Strategies (ES):** Focuses on optimizing real-valued parameters.

**The Cycle (Algorithm Steps):**

1. **Initialization:** Generate a random population of solutions.
2. **Fitness Evaluation:** Score each solution (Survival of the fittest).
3. **Selection:** Pick the best solutions to be parents.
4. **Recombination (Crossover):** Mix parts of two parents to create offspring.
5. **Mutation:** Randomly change small parts of the offspring (introduces diversity).
6. **Loop:** Repeat until the optimal solution is found.

**Question 9 (b): Write a short note on Dempster-Shafer Theory.**

**Dempster-Shafer Theory (DST)**, also known as the **Theory of Belief Functions**, is a mathematical framework for reasoning with uncertainty.
Why use it instead of Probability?
Standard probability cannot distinguish between "uncertainty" (outcome is random) and "ignorance" (we have no data). DST handles Ignorance very well.
• *Probability:* If P(Heads) = 0.6, then P(Tails) *must* be 0.4.
• *DST:* I can say belief(Heads) = 0.6, and belief(Tails) = 0.0. The remaining 0.4 is "Unassigned" (Ignorance).
**Key Concepts:**

**Belief ($Bel$) & Plausibility ($Pl$):** Instead of a single number, DST gives an interval:

- **Belief ($Bel$):** The lower bound (How much evidence *definitely* supports X).
- **Plausibility ($Pl$):** The upper bound (How much evidence *could possibly* support X).
- **Uncertainty Interval:** $[Bel(A), Pl(A)]$.
- **Application:** It is widely used in **Sensor Fusion** (combining data from cameras, lidar, and radar in self-driving cars) because it combines conflicting evidence effectively.